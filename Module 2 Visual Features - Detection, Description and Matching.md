# Module 2: Visual Features - Detection, Description and Matching

### **1.Image Features and Feature Detectors**

本章节通过描述图像上的某些**独特**像素点或小区域，来表示整个图像的特征。为了描述这些特征点需要解决以下问题：

- where：如何从图像上定位这些特征点——特征检测
- what：如何提取这些特征点的特征或如何定量的描述这些特征点——特征描述子
- 最后如何匹配不同图片上的相同特征点——特征匹配

#### **1.1 特征检测(Feature Detectors)**

什么是特征:**Features are points of interest in an image**. 

一个好的特征点(point of interest)需要满足什么性质？

- saliency：特征需要是独特的，易于分辨的。特别是和**周围的点有很明显的区别**。比如纯白区域中有一个黑色的点就会特别明显。
- Repeatability：优秀的特征点在不同的视角、光照、色彩等条件下，也应该能重复出现。这个涉及到特征提取中一个很重要的特质：invariant。
- Locality：局部的特征不会因为远处的改变而发生大的变化。
- Quantity：如果要描述整个图像，那么特征点就要足够丰富。且许多图像处理算法想要获得好的效果也要求特征足够丰富。
- Efficiency：计算效率与前面的特质相比我觉得是锦上添花。

图像的梯度特征会比图像的纹理特征独特。但是单一方向的图像梯度，比如两条水平的斑马线在单一方向的图像梯度特征也不够独特。那么多方向（>=2）的图像梯度，将会是比较好的图像特征。而多个方向的梯度，提取的特征即是常见的**角点特征**（corner）。

![image-20210824200750190](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210824200750190.png)

**常见的特征检测算法：**

- Harris: 同时提取图片的x轴的梯度和y轴的梯度。最基础的角点检测算法，但是不能保证尺度不变性。
- Harris-Laplace: Harris的改进，使用图像的拉普拉斯金字塔特征，来保证尺度不变性。
- LOG、DOG...

#### **1.2 特征描述子(Feature Descriptors)**

什么是特征描述子:特征的**位置信息 + 特征向量**。在图片上，用图片上的像素坐标$(u,v)$表示特征的位置。而特征向量$f$是表征$(u,v)$附近局部信息、特征的n维向量。

![image-20210825185623821](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210825185623821.png)

优秀的特征描述子拥有以下特质：

- Repeatability。不同图片上的同一个特征点，使用相同的特征描述子提取的特征应该相似。这要求特征描述子保存各种不变性（Invariance），比如旋转（rotation）、尺度（scale）、光照（illumination）不变性。

  ![image-20210825190224142](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210825190224142.png)

- Distinctiveness:独特性

- Compactness & Efficiency:效率高，占用计算资源少

**常见的特征描述子：**

- SIFT：
- GLOH、BRIEF、ORB....

#### **1.3 特征匹配(Feature Matching)** 

得到特征点的在图片上的位置和特征向量后，可以使用暴力遍历的方法匹配不同图片上的同一特征点。即对图一上的特征点$i$,其特征向量为$f_i$，计算$i$与另外一张图片上的所有特征点的"距离"或相似度(比如均方误差)。最后找到距离最小的特征点$j$为与$i$匹配的特征点。

![image-20210825192118800](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210825192118800.png)

但是还有两个问题：

- 如果另外一张图上本来就**没有检测到对应的特征点**，因为取最小“距离”的原因。还是会为$i$点匹配一个错误的特征点，即便这个最小距离其实也很大。

  ![image-20210825192614250](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210825192614250.png)

- 如果同时有**多个特征点**与$i$点的距离都最小且距离相等，应该选择哪个点作为最终匹配对象？

  ![image-20210825192831368](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210825192831368.png)

对应第一个问题设置一个最小距离阈值$\delta_1$，所有最小距离大于阈值的点对都抛弃。对于第二个问题，找出距离$i$点最近的两个点$c、s$，定义距离比$0\le \frac{d(f_i, f_c)}{d(f_i,f_s)} \le1$，同样设置一个阈值$\delta_2$，抛弃所有距离比大于$\delta_2$的特征点对。



### **2. Outlier Rejection(剔除异常值)**

#### **2.1 异常点/外点/离群点**

异常值能极大的影响特征匹配算法的性能。假如有这样的一个定位问题模型：给出同一场景的两幅图片，且两幅图片左上角坐标原点是对齐的。求一个偏移矩阵$T=[t_u,t_v]$，该矩阵能够让图片一沿着坐标轴分别位移$t_u,t_v$后与图片二对齐。

![image-20210826193000096](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210826193000096.png)

可以使用特征点匹配的方法解决这个问题。如果用数学公式表述这个定位问题：

- 由特征匹配算法可以得到N个匹配的点对$f_i^{(1)}$和$f_i^{(2)}$。其中每个点有两个坐标$f_i=(u_i,v_i)$

- 则待求解问题为：
  $$
  u_i^{(1)} + t_u=u_i^{(2)}\\
  v_i^{(1)} + t_v=v_i^{(2)}
  $$

- 使用最小二乘法解出$T=[t_u,t_v]$
  $$
  t_u=\frac{1}{N}\sqrt{\sum(u_i^{(1)} - u_i^{(2)})^2} \\
  t_v=\frac{1}{N}\sqrt{\sum(v_i^{(1)} - v_i^{(2)})^2}
  $$
  

但是实际处理这个问题时，由于没有过滤许多异常点的原因，如下图中紫色的点匹配到了一个离谱的异常点，这是一个异常点对（前面在特征匹配中提到的加上两个阈值的方法也无法解决这种问题）。会导致最小二乘解误差很大（因为使用了像素之间的距离）。为此需要提出一种剔除异常点的方法。

![image-20210826194820411](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210826194820411.png)

#### **2.2 RANDSAC(Random Sample Consensus 随机采样一致性)算法**

RANDSAC是一种基于“模型”的剔除异常点的算法。首先RANDSAC算法基于一些假设：

- 数据模型由“外点”和“内点”组成。“外点”是不符合数据模型的数据，“内点”是符合数据模型的数据。
- 使用一定数量的“内点”就可以估计出数据模型的参数。

RANDSAC通过多次随机采样找到一组参数，该参数确定的数据模型能够包含大多数的“内点”同时也排除掉多数的"外点"。

**算法步骤（以定位问题为例）：**

- 初始化：确认最少需要采样M个数据就能确定一组数据模型的参数。对于上面的定位问题，只需要一个点对$f_i^{(1)}$和$f_i^{(2)}$就可以确定一组模型的参数$T=[t_u,t_v]$

- 迭代执行：
  - 从数据中随机采样M个数据。即随机选择一组点对。
  - 根据采样的M个数据，计算出模型的参数P。即根据点对计算偏移矩阵$T=[t_u,t_v]$
  -  根据参数P，计算除采样数据外，符合这组参数确定的数据模型的“内点”数据集C。即根据$u_i^{(1)} + t_u=u_i^{(2)}、v_i^{(1)} + t_v=v_i^{(2)}$，统计符合该公式的点对。
  - 判断数据集C的数量是否大于“内点”比例阈值或者是否达到了最大迭代次数上限。选择返回最佳“内点”数据集还是继续迭代。
- 最后：根据最终的最佳“内点”数据集计算数据模型的最优参数。

![image-20210827162239858](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210827162239858.png)

![image-20210827162300545](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210827162300545.png)



### **3. Visual Odometry（ VO 视觉里程计）**

视觉里程计通过计算同一摄像机下不同时刻多张图片的变化，来增量的估计车辆位姿的改变情况。但是由于单一相机计算无法得到物体在真实世界的尺度，视觉里程计至少还需要**另外一个传感器**的帮助。比如另外一个相机、雷达传感器...

#### **3.1 问题模型**

- 对于同一相机连续得到的N幅图片。为每两张相邻时刻的图片$I_k,I_{k-1}$估计一个旋转平移矩阵$T$
  $$
  T=\begin{bmatrix} R_{k.k-1} & t_{k,k-1} \\ 0 & 1 \end{bmatrix}
  $$
  

- 通过矩阵T可以将$I_{k-1}图像转换到$I_k$图像对应的坐标系上去。因此可以在$$I_k$上绘制k-1时刻物体的位置。

- 因此使用N-1个旋转平移矩阵$T_k$就可以从最初的图片开始一直估计k-1时刻的物体在k时刻的位置。将他们按照时刻连接起来就是物体的运动轨迹。

  ![image-20210827170105782](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210827170105782.png)

#### 3.2 算法步骤

- 给定连续的两帧图片$I_{k-1},I_k$
- 提取他们的特征$f_{k-1},f_k$，并做特征匹配
- 根据提取的特征，做两帧间物体的**运动估计**（Motion Estimation）并计算矩阵$T_k$

运动估计：

​	依据不同格式的特征，常见的运动估计有：2D-2D; 3D-3D; 3D-2D。课后编程会用到3D-2D的运动估计。

![image-20210827182416180](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210827182416180.png)

#### **3.3 3D-2D运动估计**

3D-2D运动估计模型中，已知k-1时刻物体在3维坐标系特征点的坐标$[X,Y,Z]$和k时刻物体在图像坐标系下特征点的坐标$[u,v]$。以及相机的内参矩阵K。

求3D-2D物体运动的选择偏移矩阵[R|t]。这个模型建模如下图所示：

![image-20210827183424877](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210827183424877.png)

（略）使用Perspective N Point(PNP)算法求[R|t],如下所示:

​	![image-20210827183620538](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210827183620538.png)

