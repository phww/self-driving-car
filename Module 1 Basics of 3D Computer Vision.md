# Visual Perception for Self-Driving Cars

参考视频：[Coursera](https://www.coursera.org/learn/visual-perception-self-driving-cars?specialization=self-driving-cars)

## **Module 1: Basics of 3D Computer Vision**

### 1. 小孔成像（Pine Hole Model）

小孔成像模型有两个重要的参数：**焦距（focal length）和小孔中心坐标（camera center）**。其中**焦距决定了成像的大小**，而小孔中心坐标可以帮助人们确定物体在图像上的**映射信息**。有了这两种参数就可以使用数学上的方法，确定物体在底片上的成像位置和描述图像的生成过程。进而为状态估计和目标检测等任务提供帮助。

### 2. Camera Projective Geometry（相机投影几何）

#### 建模：将真实世界的物体投影到相机的底片上

![image-20210810185223779](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210810185223779.png)

**问题**：如果称人为规定的物体所在的真实世界的坐标系为“世界”坐标，而物体在成像平面上的投影图像的坐标系为图片坐标。现在假设在世界坐标系下的某个位置$(x_c,y_c,z_c)$有一个相机镜头，求物体在相机镜头后的成像平面上的坐标。

因为小孔成像得到的图片是上下颠倒的。为了防止混淆，人为设定一个**虚拟的成像平面**代替原始的成像平面。就可以得到下图所示的相机投影模型。问题便转换为如何将世界坐标系上的点(X, Y, Z)投影到虚拟成像平面以(u，v)表示。

![image-20210810190148239](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210810191807061.png)

其中：

- 首先需要定义**世界坐标系（word coordinate）**。定义相机镜头在世界坐标系下的坐标即相机的位姿(pose)，以这个坐标为中心定义**相机坐标系$X_cY_cZ_c$（camera coordinate）**
-  之后定义成像平面$X_sY_xZ_s$（image coordinate）的坐标原点，为虚拟成像平面的中心。而虚拟成像平面的原点位于其左上角。为了做区分，下面称虚拟成像平面为**像素坐标系（pixel coordinate）**
- 定义相机坐标系和成像平面相对于Z轴的距离为**焦距f**

**投影方法：**

- 使用旋转矩阵、位移矩阵[R|t]，将世界坐标系转换为相机坐标系

- ![image-20210810194452243](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210810194452243.png)

- 使用尺度变换（scale）和偏移变换（offset）的矩阵K，将相机坐标系转换为成像坐标系。K矩阵也称为相机的**内参**，是相机自身确定的参数

  ![image-20210810194526496](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210810194526496.png)

- 因此只要定义矩阵[R|t]和矩阵K，则通过矩阵乘法可以得到世界坐标系到成像坐标系的转换矩阵$P=K @ [R|t]$

  ![image-20210810194555212](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210810194555212.png)

- 使用**齐次坐标**和转换矩阵P可以将世界坐标$(X,Y,Z,1)^T$投影到成像坐标$(x,y,z,1)$。之后将x、y坐标除以z，最终得到像素坐标系下的坐标$(u,v)$其中$u=\frac{x}{z}, v=\frac{y}{z}$

  ![image-20210810194638191](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210810194638191.png)

- 最后在实际应用中，还会遇到相机失真、像素横纵比失衡等情况。但是只需要调整矩阵K就可以解决这些问题。

**最终成像：**

上面的坐标系系转换只是将物体的坐标从世界坐标系投影到了像素坐标系。设图片大小为MxN，有了(u,v)坐标之后还需要在对应的坐标网格中填入像素值。如果只是填入0-255单通道像素，那么得到的图像就是灰度图。彩色图像还需要对3个MxN矩阵，即R、G、B通道进行像素填充

![image-20210810194818651](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210810194818651.png)

### 3. Camera Calibration(相机校正)

相机校正的目的就是获得：相机的**内外参数**，即内参矩阵K和相机的位姿矩阵[R|t]。而最基础的单相机校准的方法是通过人为测量一组世界坐标系下的点，和与其对应的像素坐标系下的点。先逆向**求转换矩阵P**，再**使用QR分解矩阵P**得到**内参矩阵K和位姿矩阵[R|t]**。如下所示，s表示伸缩比例（scale）。

![image-20210811191800488](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210811191800488.png)

- 求解转换矩阵P

  ![image-20210812191010761](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210812191010761.png)

  使用如上的check board，可以准确的从2d点坐标获取3d点坐标。然后根据两者的对应关系，求解参数方程。首先，列出方程组

  ![image-20210812191350747](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210812191350747.png)

  之后将等式（3）带入等式（1）（2）中，得到：

  ![image-20210812191459391](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210812191459391.png)

  使用矩阵表示以上结果：

  ![image-20210812191533001](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210812191533001.png)

  如果选取了**N个点**进行校正，那么将会得到**2*N个齐次线性方程组**。解这样的齐次线性方程组可以使用求广义逆矩阵、奇异值分解等方法获得最小二乘解。

- 分解矩阵P得到相机的内参矩阵K和外参（位姿）矩阵[R|t]

  首先，如果相机中心在世界坐标系下的坐标向量为C。则将其投影到相机的成像坐标系时，这个点刚好是成像坐标系的零点。因此PC=0.所以有以下公式：

  ![image-20210812193322892](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210812193322892.png)

  得出平移矩阵t=-RC后，带入原式$P=K @ [R|t]$中有：

  ![](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210812193533635.png)

  令矩阵M=KR，则$P=[M|-MC]$​，其中M是一个方阵。根据矩阵论，任何一个n阶方阵都可以分解为n阶的上三角矩阵和n阶正交基的乘积。因此M=$R$​Q=KR，其中**$R$​为上三角矩阵**，**Q为正交基**。进一步可以认为，**上三角矩阵$R$​和内参矩阵K相等。而正交基Q和旋转矩阵R相等**。而平移矩阵t=-RC，M=KR->R=$K^{-1}M$​。则t=$K^{-1}MC$​=$K^{-1}P[:,4]$​​​。转换过程如下：
  
  ![image-20210812194828899](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210812194828899.png)

### 4.图像滤波（filter）、互相关和卷积（ Cross Correlation/ Convolution）

图像滤波有许多内容，这里只记录原理。

**filter kernel**

定义filter kernel为NxN的窗口。将这个窗口在图片上滑动，并按照一定的规则计算窗口内的像素。公式如下：$G[u,v]=HI[u-i][v-j]，其中-N<=i、j<=N$。简记为$G=HI$

其中u,v对应窗口内的中心像素的坐标，窗口内其他像素的坐标用[u-i]\[v-j]表示，注意i和j的取值范围。因此G[u,v]代表原始图像中以[u,v]像素为中心周围NxN范围内的像素经过特定的滤波操作F后的输出。

如下图，这里的滤波操作F:使用窗口内所有像素的均值作为中心[u,v]像素的输出。使用这种滤波操作，可以有效的去除图片的椒盐噪声。

![image-20210819171232387](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210819171232387.png)

**互相关和卷积**

**互相关操作定义为**：在filter kernel中填充NxN的数值，然后定义滤波操作H为$G[u,v]=\sum_{i=-k} ^{k}\sum_{j=-k}^kH[i][j]I[u-i][v-j]$，简记为$G=H\bigotimes I$。可以理解为对应窗口内 kernel 和图像像素对应位置的元素相乘在相加得到的数值作为G[u,v]的输出，如下所示：

![image-20210819172331181](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210819172331181.png)

**卷积的定义为**:将kernel先水平和垂直翻转（即沿着kernel的主对角线将kernel对应的位置的元素交换），然后再使用互相关的滤波操作，简记为简记为$G=H\ast I$

![image-20210819173141191](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210819173141191.png)

如过定义翻转操作为F，则卷积计算公式可表示为$H*(F*I)$。因为卷积是**相关联的（associative？？）**，则$(H*F)*I$。定义新的滤波操作为$\hat H=H*F$，则卷积操作的公式依然是$G=H*I$

注：当filter kernel上下左右对称时，卷积和互相关的结果就没有区别了

**应用**

- 针对不同的噪点类型使用各种对应的filter，对图片进行降噪。

- 使用互相关，进行摸板匹配。将模板与图片做互相关后，输出G[u,v]中元素最大的位置[u,v]就是摸板在图片中匹配位置的中心。

  ![image-20210819191629668](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210819191629668.png)

- 使用各种卷积核提取图片的特征，因为卷积的相关性。因此可以将提取多种特征的卷积核依次与原始图片做卷积操作，最终得到更加抽象的特征。

  ![image-20210819191648255](https://pic-1305686174.cos.ap-nanjing.myqcloud.com/image-20210819191648255.png)

**CNN中的迷惑**

​	之前学习CNN时，总结的卷积操作就是窗口内卷积核和图片对应位置的元素相乘再相加（加权求和）。严格来说这是互相关操作。但是CNN中由于是卷积核自学习核内的参数，因此严格使用互相关或卷积操作训练出来的卷积核，最后的差别应该就是参数的位置顺序。因此CNN中严格使用互相关或卷积的差别不大，严格使用自相关还能省下严格卷积的旋转操作。

但是在图像处理领域中一定要区分这两种概念！！有一些中文教程，没有区分这两种概念，就很迷惑。。。

